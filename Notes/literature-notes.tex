\documentclass{article}

\input{commands}
\usepackage{outlines}
\usepackage{parskip}
\usepackage{natbib}
% \usepackage{bibentry}

\newcommand{\qt}{}
\newcommand{\graddel}[2]{\frac{\del #1}{\del #2}}
\newcommand{\hessdel}[3]{\frac{\del^2 #1}{\del #2 \del #3}}

% Page Layout
\setlength{\oddsidemargin}{0.0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8in}
%\parindent 0in
%\parskip 12pt

% Set Fancy Style
\pagestyle{fancy}

%\lhead{Left Header}
%\rhead{Right Header}

\begin{document}

% We need this to place the references in the notes.
% \nobibliography{bayeslogit}{}
%\bibliographystyle{abbrvnat}

% Change Font and Spacing
%\large % change the font size to 12pt
%\linespread{1.1} % change the line spacing

% Set the counter
% \setcounter{section}{0}

\tableofcontents

\section{Albert and Chib, 1993}

Bayesian Analysis of Binary and Polychotomous Response Data:

\begin{outline}
\1 Model: binary response $y_i \sim Bern(p_i)$ where $p_i = H(x_i \beta)$.
\2 We get to chose $H$.  $H =$ cdf of Normal: Probit.  $H=$ logistic: Logit.

\1 Normal approximation to likelihood not good for small $n$.

\1 Key idea: see a function of $x_i \beta$ and make it an integral over some
density.
\2 L: $\prod \Phi(x_i \beta)^{y_i} (1 - \Phi(x_i \beta))^{1-y_i}$.  So
\begin{align*}
\Phi(x_i \beta) 
& = \int_\bbR \bbI_{(-\infty, x_i \beta]}(z) p(z \mid 0, 1) dz 
= \int_\bbR \bbI_{[-x_i \beta, \infty)}(z) p(z \mid 0, 1) dz \\
& = \int_\bbR \bbI_{[0, \infty)}(z) p(z, \mid x_i \beta, 1) dz
\end{align*}
Similarly, $(1-\phi(x_i \beta)) = \int_\bbR \bbI_{(-\infty,x_i \beta]} p(z \mid
x_i \beta, 1)$.
Since
\[
p(\beta | y) = \int p(\beta, z \mid y) dz = \int p(\beta \mid y) p(z \mid \beta,y) dz.
\]
We have
\[
p(\beta, z | y) = \prod p(z_i \mid x_i \beta, y_i)
\]
where $p(z_i \mid x_i \beta, y_i)$ is standard normal with mean $x_i \beta$,
right truncated at zero if $y_i = 0$ and standard normal with mean $x_i \beta$,
left truncated if $y_i=1$.  Equivalently, and this is direct from Albert and
Chib
\[
\prod \Big[ \bbI(z_i > 0, y_i=1) + \bbI(z_i < 0, y_i=0) \Big] p(z_i \mid x_i
\beta, 1).
\]
In this scenario, the posterior conditionals are ``nice'' and you can then use
Gibbs sampling.

\2 You can generalize this further, by mixing the normal $N(z_i \mid x_i \beta,
\lambda)$ over $\lambda$.  They also delve into a hierarchical, e.g. Lindley and
Smith discussion, so that there is a hyperprior on the prior mean for $\beta$.

\1 Also discussion multinomial probit data.

\end{outline}

\section{Held and Holmes, 2006}

Bayesian Auxiliary Variable Models for Binary and Multinomial Regression

\begin{outline}

\1 Overal impression: they do several things: can just tick off the same stuff
with Polson and Scott's auxillery approach.

  \2 Auxillery variable representation

  \2 Joint sampling approach

  \2 Covariate uncertainty (model selection)

  \2 Polychotomous regression

\1 Extension to Alberta and Chib, 1993.

  \2 Joint Update

  \2 Auxillery approach is possible for logistic, using scale mixture of
  Normals.

    \3 Logit model is preferred because you can interpret stuff in terms of
    log-odds.

    \3 Logit link is analytic and has relatively heavy tails

  \2 Their logit work can be generalized to accomodate covariate set uncertainty
  and multinomail response data.

\1 For probit: they suggest a ``joint'' draw, which uses
\[
p(\beta, z |y) = p(z |y) p(\beta | z)
\]
instead of the Gibbs steps 1) $p(\beta | z, y)$ 2) $p(z | beta, y)$.  Joint is
in quotations because they use Gibbs sampling to draw $p(z|y)$.

  \2 Empirically, this is more efficient.

\1 Logit: They follow probit method, but you need another auxillery variable.
\begin{align*}
y_i & = \{ 1, z_i > 0; 0, z_i \leq 0 \} \\
z_i & = x_i \beta + \ep_i \\
\ep_i & \sim N(0, \lambda_i) \\
\lambda_I & = (2 \psi_i)^2 \\
\psi_i & \sim KS \\
\beta & \sim p(\beta)
\end{align*}
Of course, Devroye (1986), knows how to draw a Kolmogorov-Smirnov (KS)
distribution.  Once you have marginalized $\lambda$ you get that
$\ep_i$ is logistic, which Andrews and Mallows discuss.

  \2 Can sample kind of jointly.  A couple options.  They suggest $p(z, \lambda
  | \beta y)$ and $p(\beta | z, \lambda)$.

\1 What is going on in (16)?  Why not just take the $\beta_j$ of interest from
the the posterior?

\1 Check out discussion.  Mentions alternative method by Gamerman (1997) that
uses a ``weighted least squares'' Metropolis-Hastings proposal.

\end{outline}

\section{Andrews and Mallows, 1974}

Scale Mixtures of Normal Distributions

\begin{outline}

\1 Key connection:  If $Z \sim N(0,1) \perp V$ and $X = Z/V$ then $X$ has a
density given by
\begin{equation}
\label{am74:scale-mixture}
f_X(x) = (2 \pi)^{-1/2} \int_0^\infty v 
\exp \big\{ -\frac{1}{2} v^2 x^2 \big\} dG_V(v).
\end{equation}

\1 One can connect this to the Laplace transform of $H$, $h(y) = f_X(\sqrt{y})$
where
\[
H(t) = \int_0^t (u/\pi)^{1/2} dG_v[(2u)^{1/2}].
\]
Thus $f \rightarrow h \rightarrow H \rightarrow G$.

  \2 Similarly, if you know $f_X$ then you can immediately calculate the Laplace
  transform of $G$ (i.e. Moment generating function of $V$) by
  \[
  2 \int_0^\infty f_X(x) \exp \big\{ -\frac{1}{2} t^2 / x^2 \big\}
  =
  \int_0^\infty \exp (-vt) dG_V(v)
  \]
  using the identity
  \[
  \int_0^\infty \exp \Big( -\frac{1}{2} (a^2 u^2 b^2 u^{-2}) \Big)
  =
  (\pi/2a^2)^{1/2} \exp (-|ab|).
  \]

\1 \textbf{Main theorem}: Suppose $f_X$ is symmetric.  Then $g(y) =
f_X(y^{1/2})$ is totally monotone iff you can write $X$ as $Z/V$ where $Z \perp
V$ and $Z$ is standard normal.

  \2 This is all about BERSTEIN's theorem, which is interesting in its own
  right!

  \2 Totally monotone: 
  \[
  (-1)^n \frac{d^n f}{dy} \geq 0 \textmd{ for } y > 0.
  \]

  \2 BERSTEIN's theorem: If $f \in C^\infty\{ [0, \infty) \}$ is totally
  monotone then you can write $f$ as a mixture of exponentials:
  \[
  f(t) = \int_0^\infty e^{-tx} dg(x).
  \]

  \3 This theory characterizes the Laplace transforms of Borel meausres on the
  positive reals.

  \3 This is related to Levy processes and infinitely divisible measures (for
  subordinators, I suppose).

  \2 Their theorem includes a nice application of the MCT.

\1 Several examples: t, double exponential (Laplace), and logistic distribution.

\end{outline}

\section{Fruhwirth-Schnatter and Fruhwirth, 2007}

Auxiliary mixture sampling with applications to logistic models

\begin{outline}

\1 Second paragraph of intro mention ``seminal papers on Bayesian estimation of
logistic regression models''

  \2 First sampling? Zellner and Rossi, 1984

  \2 First MCMC: Zeger and Karim, 1991

  \2 Other MCMC: Gammerman, 1997; Chib et al., 1998, Lenk and DeSarbo, 2000;
  Hurn et al., 2003; Scott, 2004

  \2 Review: Dey et al., 2000.

\1 Mention again that most MCMC techniques require M-H step, which is evidently
not prefered.  Criticize Holmes and Held for using M-H step.

\1 Strategy: use latent utilities approach (McFadden, 1974) and (Scott, 2004) to
turn into a (conditionally) linear model; use normal mixture to approximate type
I extreme value distribution.

  \2 Latent utility thing is confusing economic-speak.  Just think of as latent
  varibles.

  \2 Equivalent to logit: 
  \begin{displaymath}
  \begin{cases}
    y_i = \bbI \big\{y_i^u > y_{i0}^u \big\} & \\
    y_i^u = x_i \beta + \ep_i & \\
    \ep_i, y_{i0}^u \sim \textmd{Type I Extreme Value Distributions} &
  \end{cases}
  \end{displaymath}

  Use normal mixture to approximate $\ep_i \approx N(m_{r_i},
  V_{r_i})$.  Then one can estimate $\beta$, in a Gibbs sampler using
  \[
  y_i^u = x_i \beta + m_{r_i} + N(0, V_{r_i}).
  \]

\1 Notes on Normal Mixture:

  \2 Pick values for normal mixture by minimizing Kullback-Leibler distance or
  Maximum absolute deviation.

  \2 Test how well normal mixture approximates true density by running a MCMC
  Met. Hast. simulation and measuring acceptance rate.  (SOMETHING TO REMEMBER.)

\1 Key link between type I extreme value distribution and exponentials.  In
particular,

  \2 $z \sim EV(I) \implies \exp(-z) \sim Ex(1) \sim Ex(rate=\exp(z))$.  Thus
  one can work with exponentials instead of EV(I) since we have a monotone
  transform which preserves the inequality.

  \2 Several key facts.

  \3 $\exp(-y_i^u) = \exp(-x_i \beta - \ep_i) = \frac{1}{\lambda_i} \exp(-\ep_i) \sim
  E(\lambda_i).$

  \3 $x_1 \sim E(\lambda_1)$ and $x_2 \sim E(\lambda_2)$ implies 
  $x_3 = \min(x_1, x_2) \sim E(\lambda_3 = \lambda_1 + \lambda_2)$
  And
  \[
  \begin{cases}
  p(x_1 | x_1 < x_2) \sim E(\lambda_3) \\
  p(x_1 | x_1 > x_2) \sim x_2 + E(\lambda_1).
  \end{cases}
  \]

  For my own sanity: The trick to use: think about $P(X_1 > x_1, etc.)$.  To
  show the min: $P(M:=\min\{X_1,X_2\} > x) = P(X_1 > x, X_2 > x)$ to get cdf.  To
  show conditionals, use similar trick:
  \begin{align*}
  P(X_1 > x, M > y) & = P(X_1 > x, X_1 > y, X_2 > y) \\
  & =
  \begin{cases}
    P(X_1 > x, X_2 > y) = e^{-\lambda x} e^{-\gamma y} &, x \geq y \\
    P(X_1 > y, X_2 > y) = e^{-(\lambda + \gamma)x} &, y > x.
  \end{cases}
  \end{align*}
  To get the density we apply $\frac{-\del}{\del x} \frac{-\del}{\del y}$ above
  to get the density
  \[
  p(x,y) =
  \begin{cases}
    \lambda e^{ -\lambda x} \gamma e^{ - \gamma y} &, x \geq y \\
    0 &, y > x.
  \end{cases}
  \]
  The kernel for the conditional is then
  \[
  \begin{cases}
    e^{-(\lambda + \gamma)x} &, x=y \\
    e^{-\lambda x} &, x > y.
  \end{cases}
  \]

\1 \textbf{Everything you need to implement code} is on pp. 3512 and 3513.

  \2 Key thing!  You must sample $(y^u, r \mid, e.e.)$ jointly!

\1 Multinomial logit

  \2 Direct extension of logistic regression for binary outcomes.

  To remind myself: One view of the multinomial case: $\mb{y}_i = (y_{i1},
  \ldots, y_{im})$ with each componenent representing the number of instances of
  case $j$ on the $i$th trial.

  I believe in FS\&F we must restrict our attention to ``one roll of the
  die,'' in which case we just get only one observation be trial.  In that case
  we can identify $y_i$ by the catogory $k$ we observe.

  We now have $m$ latents with
  \[
  y_{ji}^u = x_i \beta_j + \ep_{ji}, \ep_{ji} \sim EV(I), j = 1, \ldots m
  \]
  as well as $y_{0i}^u \sim EV(I)$.  Then
  \[
  y_i = k \iff y_{ki}^u = \max_{\ell} y_{\ell i}^u.
  \]
  This is due to McFadden, 1974.

  They say ``the category 0 for observation $y_i$ is indenpendent of any
  covariates for reasons of identifiability.''  Thinking along previous lines,
  one way to identify model is to chose $\lambda_0 = 0$, i.e. $\beta = 0$, which
  can be seen as $y_{0i}^u = \ep_{0i}$.

  In the case above we have two outcomes. Here it would seem that really we have
  $m+1$ outcomes.

  \2 Posterior estimation in essentially the same way:

    \3 Use normal mixture trick to represent some of the EV(I)'s.

    \[
    y_{ki}^u = x_i \beta_k + m_{r_{ki}} + N(0, s_{r_{ki}}^2).
    \]

    \3 Use exponential trick to sample $y_i^u | y_i, \beta)$.

    We know $\exp(-y_{ki}^u) = Ex(\lambda_{ki})$ with the convention that
    $\lambda_0 = 1$.  Further,
    \[
    \min_k \Big\{ \exp(-y_{ki}^u) \Big\} \sim Ex( \sum_{k=0}^m \lambda_{ki} ).
    \]
    
    When $y_i = k$ we know that 

    \4 $\exp(-y_{ki}^u) = \min \cdots$ with the above distribution and that
    
    \4 $\exp(-y_{\ell i}^u) = \exp(-y_{ki}^u) + Ex(\lambda_{\ell i})$.

    \3 Sample the normal mixture in the same way.

\1 Two extensions to more complex models:

  \2 State space modeling of binary data

  \2 Multinomial logit models with random effects

\1 Applications...

\end{outline}

\section{Fruhwirth-Schnatter and Wagner, 2006}

Title: Auxiliary mixture sampling for parameter-driven models of time series of counts
with applications to state space modelling

Citation: \cite{fruhwirth-schnatter-wagner-2006}

BibKey: fruhwirth-schnatter-wagner-2006

\begin{outline}

\1 Poisson regression for counts with mean changing in time

\[
y_t \mid \lambda_t \sim Po(\lambda_t), \; \log \lambda_t = x_t \beta.
\]

  \2 Usually, observations are assumed to be independent.

  \2 Account for dependence by (1) parameter-driven or (2) observation-driven
  models.  (See Cox, 1981).

  \2 They consider \emph{parameter} driven, in which case dependence is
  introduced by latent process.

\1 p.2, 2nd paragraph, references.

\1 There general model is
\[
\begin{cases}
y_t \mid \lambda_t \sim Po(\lambda_t) \\
\log \lambda_t = x_t^1 \alpha + x_t^2 \beta_t \\
x_t \sim \textmd{ some time series } \sim p(x\mid\theta).
\end{cases}
\]
The model for $x_t$ is what ``ties'' the means $\lambda_t$ together across
observations.

  \2 Two tricks: latent exponentials and normal mixtures.

  Consider the density for $y_t$.  Check Sato: You can construct the Poisson procoess
  $X_t$ using the random walk $W_n = T_n + W_{n-1}$ where $T_n \sim E(\lambda)$
  and $X_u = n$ iff $W_n \leq u < W_{n+1}$.  $X_u$ as marginal distribution
  $Po(\lambda u)$.  Thus if $y_t \sim Po(\lambda_t)$ then we must have that
  $P(y_t = n \mid \lambda_t) = P(W_{n} \leq 1 < W_{n+1} \mid \lambda_t)$.

  More specifically, it would be something like for each day $t$ we have
  $y_{t,u}$, a Poisson process in $u$ with parameter $\lambda_t$.  You can then
  say that $y_{t,1}$, which we denote $y_{t}$ for short, has
  \[
  P(y_t = n | \lambda_t) = P(W_{n}^{(t)} \leq 1 < W_{n+1}^{(t)} | \lambda_t)
  \]

  Analogous to $W_n^j$ above consider the latents $\tau_{tj} \sim E(\lambda_t),
  j = 1, \ldots, y_t + 1$.  Then
  \[
  \tau_{tj} \sim \frac{\xi_{tj}}{\lambda_t}, \; \xi_{tj} \sim Ex(1).
  \]
  You can do inference on $\log \lambda_t = \alpha x^1_t + \beta_t x^2_t$ by
  considering the log transformation,
  \[
  - \log \tau_{tj} \mid \alpha, \beta_t = x_t^1 \alpha + x_t^2 \beta_t + \ep_{tj}
  \]
  \textbf{ where }
  \[
  \ep_{tj} = - \log \xi_{tj} \sim \textmd{Extreme Value, model by exponential mixture.}
  \]
  Presumably $\beta_t$ is coming from a random walk, AR(1), etc.

  \2 Inference (my impression)

    \3 Sample $\alpha, \{\beta_t\}$ given $\{\tau_{ij}\}, \theta$ using DLM stuff.
    \3 Sample $\theta$ (from $\beta_t \sim AR(1|\theta)$) using time series stuff.
    \3 Sample normal mixture indicators $r_{tj} | \alpha, \beta_t, \tau_{tj}$.
    \3 Recall that $\log \lambda_t = \alpha x^1_t + \beta_t x_t^2$.
    \3 Sample $\tau_{tj} | \{y_{t}\}, \lambda_t$ using knowledge about
    conditional distribution of $\tau_{tj}$, i.e. $W_{y_t} = \sum_{i=1}^{y_t}
    \tau_{tj}$ has $W_{y_t} \leq 1 < W_{y_t+1}$.  Evidently, you can do this
    using order statistics... see Robert \& Casella, 1999, p. 47.


  \2 FS\& say to do the following:

  Select starting values for $\tau, \theta$ and $S = \{r_{tj}, j=1, \ldots, y_t,
  t=1, \ldots, T\}$.  (Aside: from my experience you want to be smart about
  seeding the indicators $\{r_{tj}\}$.  In particular, you DO NOT want to start
  the seed at a highly unlikely spot.  That can throw your entire simulation off
  into some other local mode.  [Or something like that.  I'm not exactly sure
  what happens.]  You could start by randomly picking $\{r_{tj}\}$ be prior
  distribution.)

    \3 Sample $\alpha, \{\beta_t\} | \ldots$.
    \3 Sample $\theta | \ldots$.
    \3 Sample $\{\tau_{tj}\} | \ldots$.
    \3 Sample $\{r_{tj}\} | \ldots$.
  
\1 Example: Application to road safety.

\end{outline}

\section{Geyer, 1992}

Title: Practical Markov Chain Monte Carlo

Citation: \cite{geyer-1992}

BibKey: geyer-1992

\begin{outline}

\1 Lots of good references in the beginning.

\1 If you run several chains and they disagree, then you haven't run your chains
for a long enough period.

  \2 But ``no comfort should be taken from the agreement of multiple runs.''

  \2 N. Polson, ``witch's hat'' distribution.

\1 p. 474 right side: ``Metropolis-rejected swapping'' (Geyer, 1991a) and other variants on
Metropolis methods.

\1 Theorem due to Kipnis and Varadhan, 1986: you can show that the moment of the
chain $\hat \mu_n$ and the moment you are interested in satisfy some central
limit result (p. 475).

In particular,
\[
\sqrt{n} (\hat \mu_n - \mu) \ra_{\mcD} N(0, \sigma^2).
\]

However, for this to be useful you need an estimate of $\sigma^2 =
\sum_{t=-\infty}^\infty \gamma_t$, the sum of the autocorrelations.

Just using the corresponding sample quantities does not work though.  However,
$\Gamma_m = \gamma_{2m} + \gamma_{2m+1}$ possess special properties (positive,
monotone decreasing, and convex), which can be used to select some ``good''
terms to generate an upper bound for $\sigma^2$.

\end{outline}

\section{West et al. 1985}

Title: Dynamic Generalized Linear Models and Bayesian Forecasting.

Citation: \cite{west-etal-1985}

BibKey: west-etal-1985

\begin{outline}

\1 Brief history of genesis: static to dynamic; formalize management by exception.

\1 Exponential family:
\[
p(Y_t \mid \eta_t, \phi) = \exp \Big[ \phi \Big\{Y_t \eta_t - a(\eta_t)\Big\}
\Big]
b(Y_t, \phi).
\]
$\eta_t$ is called the natrual parameter and $\phi$ is a scale parameter.  The
mean and variance are described by
\[
\bbE[Y_t \mid \eta_t, \phi] = \mu_t = a'(\eta_t)
\]
and
\[
\Var[Y_t \mid \eta_t, \phi] = a''(\eta_t) / \phi.
\]
If the prior for $\eta_t$ takes a specific form then closed form Bayesian
forecasting is possible.  That form is
\[
p(\eta_t | D_{t-1}) = c(a_t, \beta_t) 
\exp \Big[ a_t \eta_t - \beta_t a(\eta_t) \Big].
\]

\1 You can find a recapitulation of this work in \cite{harrison-west-1997}.

The idea there is to proceed using clever approximations.  With a generalized
linear model you want to model the conditional mean.
\[
\bbE[Y_t | \beta] = \mu_t(\beta) = a'(\eta_t).
\]
But the conditional distribution $p(Y_t | \beta)$ is not normal.  One does not
want to relate $\mu_t$ to $\beta$ in a linear way because that will probably
force $\mu_t$ to potentially take on some values that should have zero
probability.  Instead, one wants to use some transform taking $\mu_t$ to
$\lambda_t$ and to model $\lambda_t = x_t \beta$ linearly.  I believe $a'$ is
usually (always?) strictly increasing.  Let $\lambda_t = h(\mu_t)$ and
$\lambda_t = g(\eta_t)$ be bijections.  Then we can go between $\mu_t, \eta_t$,
and $\lambda_t$ with $a', h$, and $g$.  In binary logistic regression the
natural paramter is the log-odds so $g$ is the identity in that case.

\2 On p. 521 you see that
\[
\begin{cases}
p(Y_t | \eta_t) \; \text{ and } \; g(\eta_t) = \lambda_t = F_t' \theta_t \\
\theta_t = G_t \theta_{t-1} + \omega_t \; \text{ with } \; \omega_t \sim [0, W_t].
\end{cases}
\]
Notice that now the observatione equation is not just a normal perturbation and
that the distribution of $\omega_t$ is unspecified; instead, the first and
second moments are given.

If the time $t-1$ posterior moments are
\[
(\theta_{t-1} | D_{t-1}) \sim [m_{t-1}, C_{t-1}]
\]
then one evolves forward to
\[
(\theta_t | D_{t-1}) \sim [a_t, R_t]
\]
just like in the normal case.  But now we are just working with moments instead
of distributions.  The joint moments of $lambda_t$ and $\theta_t$ are then
\[
\begin{pmatrix} \lambda_t \\ \theta_t \end{pmatrix} | D_{t-1}
\sim
\Big[
\begin{pmatrix} f_t \\ a_t \end{pmatrix},
\begin{pmatrix}q_t & F_t' R_t \\ R_t F_t & R_t \end{pmatrix} \Big].
\]
One may take these moments and produce the regression of $\theta_t$ upon
$\lambda_t$ to calculate $\hat \bbE[ \theta_t | \lambda_t, D_{t-1}]$ and $\hat
\bbV[ \theta_t | \lambda_t, D_{t-1}]$.  I think you can derive these quantities
using linear predictors and quadratic loss.  (See section 4.9.)  In that case
I'm not sure if $\bbV(\theta_t | \lambda_t, D_{t-1})$ has the meaning that one
would initially give it.

They suggest using a conjugate distribution for $\eta_t$ so that one may go from
$(\eta_t | D_{t-1})$ to $(\eta_t | D_t)$ in a convenient way.  Think of this in
the following way.  The distribution of $(\eta_t | D_{t-1})$ is described by
$(r_t, s_t)$.  You update with new data to get new parameters $(r_t^*, s_t^*)$.
So the program to this point would be:

\begin{enumerate}
\item Get moments of $\lambda_t | D_{t-1}$.  Use those moments to calculate
  $r_t$ and $s_t$.

\item Use $r_t$ and $s_t$ to get $r_t^*$ and $s_t^*$.

\item Use $r_t^*$ and $s_t^*$ to get $f_t^*$ and $q_t^*$ where
\[
f_t^* = \bbE[\lambda_t | D_t] \; \text{ and } \; q_t^* = \Var[\lambda_t | D_t].
\]  
\end{enumerate}

Evidently, one can show that
\[
p(\theta_t | D_t) = \int p(\theta_t | \lambda_t, D_{t-1}) p(\lambda_t | D_t) d \lambda_t.
\]
This shows that $p(\theta_t | \lambda_t, D_t) = p(\theta_t | \lambda_t D_{t-1})$
I think.  That lets us then do
\[
\bbE[\theta_t | D_t] = \bbE[ \bbE[ \theta_t | \lambda_t, D_{t-1}] ]
\]
and
\[
\bbV[\theta_t | D_{t}] = 
\bbV[ \bbE[ \theta_t | \lambda_t, D_{t-1}] | D_{t} ] + 
\bbE[ \bbV[\theta_t | \lambda_t, D_{t-1}] | D_t ].
\]
We have linear estimates $\hat \bbE[\ldots] \simeq \bbE[\theta_t | \lambda_t,
D_{t-1}]$ (as an affine function of $\lambda_t$, and a function of $\lambda_t$,
$f_t$, and $q_t$) and $\hat \bbV[\ldots] \simeq \bbV[\theta_t | \lambda_t,
D_{t-1}]$ (as a function of $q_t$).  We can use those to get approximates
versions of $\bbE[\theta_t | D_{t}]$ and $\bbV[\theta_t | D_t]$.  Calculating
the approximation yields $(\theta_t | D_t) \simeq [m_t, C_t]$.

So the two places we must fiddle with things: (1) when we assume $\eta_t$ is
conjugate to $Y_t$, which I suppose isn't that crazy, except that I don't see
why it should be conjugate \emph{and} the transformed parameters should follow a
certain process; (2) we use the linear moments instead of the actual moments.

Thus, this procedure is really moving between \emph{approximations} of the first
and second moment.

\end{outline}

\section{Ravines Et al., 2006}

Title: An Efficient Sampling Scheme for Generalized Dynamic Models

Citation: \cite{ravines-etal-2006}

Bibkey: ravines-etal-2006

Building upon the work of \cite{west-etal-1985}, \cite{ravines-etal-2006} take
their sampling scheme and then add an MCMC step to get an exact draw from the
joint distribution of the states.

In particular, one assumes that the approximate moments produced by the above
procedure are exact and then backwards samples as in the normal case using
\[
p(\theta_T | D_T) \prod_{i=1}^T p(\theta_{t-1} | \theta_{t}, D_{t-1})
\]
where, I believe one uses the approximate moments $m_{t-1} = m_{t-1}(D_{t-1})$
and $C_{t-1} = C_{t-1}(D_{t-1})$ to evolve $\theta_{t-1}$ and then calculate the
regression coefficients needed for the backwards sampling.

Papers they mention:

\begin{outline}

\1 A review: Ferreira and Gamerman (2000).

\1 Prior to MCMC

\2 West et al. (1985)
\2 Kitagawa (1987)
\2 Farrmeir (1992)

\1 Migon (2005) has a survey?

\1 MCMC 
\2 Gamerman (1998) - studied MH methods.  Found single move samplers to be better.

\2 Geweke and Tanizaki (2001) - proposed some extensions.  Focused on good
proposals.

\end{outline}

Their contribution: proposing a multimove sampler.

\section{Fruhwirth-Schnatter and Fruhwirth, 2010}

Title: Data Augmentation and MCMC for Binary and Multinomial Logit Models. 

Citation: \cite{fruhwirth-schnatter-fruhwirth-2010}

BibKey: fruhwirth-schnatter-fruhwirth-2010

Good review of Bayesian methods for estimation in binary and multinomial logit.

\begin{outline}

\1 Review Holmes and Held and FS\&F along with several MH methods

\1 Scott's independnet MH methods is the best.

\2 I think the advantages of independent MH are going to go away when we are
working in the dynamic case.

\1 FS\&F present a normal mixture for the logistic distribution, a la the HH
auxiliar representation, which does much better than the FS\&F representation in
terms of extreme values.

\2 They call representation with logistic error DRUM and the representation with
EV error RUM (random utility).  You can derive the DRUM representation from RUM:
the logistic distribution can be written as the difference of two extreme value
distributions.

\1 From this point, it would seem that our challenge is to beat MH.  That may
not be possible.

\1 HH does horrible in their paper.  I am guessing that they did not implement the
HH stuff in C.

\end{outline}

\section{Fr\"{u}wirth-Schnatter and Wagner, 2008}

Title: Marginal liklihoods for non-Gaussian models using auxiliary mixture
sampling.

Citation: \cite{fruhwirth-schnatter-wagner-2008}

BibKey: fruhwirth-schnatter-wagner-2008

This will be of interst to James maybe.  It is about model selection for GLMs.
Use the complete-data likelihood estimator.  I need to read this more closely.

\section{Fr\"{u}wirth-Schnatter et al., 2009}

Title: Improved auxiliary mixture sampling for hierarchical models

Citation: \cite{fruhwirth-schnatter-etal-2009}

BibKey: fruhwirth-schnatter-etal-2009

The idea is that it is annoying to have to calculate all of those latent
variables in the Poisson case.  She remedies that by using a different latent
variable augmentation, though now she must approximate the $\log \text{Ga}(a,
1)$ distribution for various $a$.  She does that by generating the finite
mixture approximations for various $a$.  It appears that one could preprocess to
find the approximations.

She gives a presentation for negative binomial regression.  It appears that one
should want to select the degrees of freedom parameter.  She provides a way to
do that.  It seems to me that she is saying that she can sample from $\log
\text{Ga}(a, 1)$ for positive integers $a=1, \ldots, 20$, and then for
increasingly less frequent positive integers.  She has a way to interpolate
between those positive integers she hasn't precomputed a mixture representation
for directly.

\section{O'Brien and Dunson, 2004}

Title: Bayesian Multivariate Logistic Regression

Citation: \cite{obrien-dunson-2004}

BibKey: obrien-dunson-2004

Their moitivating example is binary logistic regression: neurtoxicology study in
rat pups.  Give rats pesticide at various levels and then observe normal
activity level (0) or elevated activity level (1).  This is odd since they are
designing a multivariate procedure.

Common frequentist approaches they mention: marginal logistic regression via
generalized estimating equations \qt{(GEE's; Zeger and Liang, 1986; Pretice, 1988,
Lipsitz, Laird, and Harrington, 1991; Carey and Zeger, 1993, among others) and
mixed effects logistic regression (Stiratelli, Laird, and Ware, 1984).}

They mention Albert and Chib-like method when working in univariate case.  Then
they say that this approach is problematic when trying to extend things to the
multivariate setting.

Their approach: Take i.d. $e_j$ with CDF $F$.  Then $\ell_j = \log \{ F(e_j) /
(1 - F(e_j)) \}$ is logistically distributed and hence $z_j = \mu_j + \ell_j$ is
logistically distributed with mean $\mu_j$.  They claim that because each $z_j$
is marginally logistic that the joint distribution of $z = \{z_j\}$ is
multivariate logistic.  I need to convince myself of that.  (I suppose you could
take Andrews and Mallows and then apply a transformation.  $X = N(0, \Lambda)$
where $\Lambda_{ii}$ is $4KS^2$.  Then define $AX$ to be multivariate logistic?
Maybe not.  Does this have logistic marginals?  It does if the sum of
independent logistic rvs is logistic.  But that does not seem to be the case
looking at the CF.  Thus it must be the multivariate logistic is defined in
terms of havign marginal logistic distributions?  Or it could be defined via the
multinomial logistic transformation--identifying that with a CDF.)

It isn't clear to me that that are doing multinomial logistic regression in the
sense that they are constructing a transformation for a generalized linear
model, but they do not show, at least I haven't found yet, that their
construction implies a likelihood invovlving
\[
\frac{e^{\psi_{ij}}}{\sum_{j=1}^J e^{\psi_{ij}}}.
\] 
Their model has the property that marginally one recovers a logistic
transformation.  I suppose when one choses a t-disribution with diagonal scale
parameter that things become independent and so you should get something like
that.  They mention multiple binary observations, which is different than
rolling a dice.

See equation (6) and discussion near by.  Theirs is slightly different.

In any event their construction of multivariate link function is interesting.
It is induced by the augmentation.  They suggest using $e \sim T_p$, a
multivarite t-distribution to construct $z$.  This induces a distribution on
$z$, and that can then be used for modeling.  Decomposing the t-distribution as
a scale-mixture of normals gets one back to a normal distribution, I am
guessing, for the regression coefficient.  (Aside, what if you use Andrews and
Mallows as suggested above with Holmes and Held to generate a link function?  Or
with our method for that matter.)

Check out Chib and Greenberg 1998 to see where they get some inspiration.

We can use there method to do a direct comparison with binary logit.  We need to
add a Metropolis step.  This is essentially in Albert and Chib 1993---use a $t$
to approximate the logistic.

If we think about a single draw from a multinomail distribution with $K$
categories, we have
\[
p_{ik} = \frac{e^{\psi_{ik}}}{1 + \sum_{k=1}^{K-1} e^{\psi_{ik}}} = F(\alpha_k)
- F(\alpha_{k-1})
\]
where the last term comes from O'Brien and Dunson.  The parameters $\alpha_k$
partition $\bbR$ to determine the probability of selecting something from group
$k$.  Thus it seems like it should be the $\alpha_k$ that are associated with
the $\beta_k$ in the multinomial case.

\section{Scott, 2011}

Title: Data augmentation, frequentist estimation, and the Bayesian analysis of
multinomial logit models

Citation: \cite{scott-2011}

BibKey: scott-2011 (I think everyone refers to a working paper from 2004)

Key papers he mentions
\begin{itemize}
\item Tanner and Wong (1987)
\item Albert and Chib (1993)
\item McCulloch and Rossi (1994)
\item Meng and van Dyk (1999)
\item Liu and Wu (1999)
\item van Dyk and Meng (2001)
\end{itemize}

He suggests three different algorithms.

\begin{description}

\item[DAFE] (Constrain $\beta_0=0$ for identifiabiltiy.)

This is Gibbs sampling--MH within Gibbs.

1. Sample $z \sim p(z | \beta^{(t)}, y)$

2. Use a MH step to sample $\beta \sim p(\beta | y,z)$.

In particular, Let your proposal be
\[
q_t(\beta) = p_\infty(\beta | \hat \beta^{(t)})
\]
where $\hat \beta^{(t)}$ is a least squares estimate of $\beta$ given $z^{(t)}$
and normal prior; and the target distribution is $p(\beta | y, z)$.

Scott uses the EV representation.  FSF say using the logistic representation is
better!!!

\item[DAFE-R]

This RW metropolis.

Just do MH.  Use the least squares estimate for the scale (I think) in the
proposal.

\item[DAFE-WP] Do DAFE but now do not constrain $\beta_0$.  Correct that in
  post-processing for identifiability.

\end{description}

\section{Hahn et al., 2010}

Title: A sparse Factor-Analytic Probit Model for Congressional Voting Patterns

Citation: \cite{hahn-etal-2010}

Bibkey: hahn-etal-2010

\section{Chib and Jeliazkov, 2006}

Title: Inference in Semiparametric Dynamic Models for Binary Longitudinal Data

Citation: \cite{chib-jeliazkov-2006}

BibKey: chib-jeliazkov-2006

\section{Chib and Greenberg, 1998}

Title: Analysis of multivariate probit models

Citation: \cite{chib-greenberg-1998}

BibKey: chib-greenberg-1998

They model \emph{correlated binary responses}.  This is not a multinomial
model.  In particular, given $Y_i = (Y_{i1}, \ldots, Y_{iJ})$,
\[
P(Y_i = y_i | \beta, \Sigma) = p(y_i | \beta, \Sigma) = 
\int_{A_{i1}} \ldots \int_{A_{iJ}} \phi_J(t | 0, \Sigma) dt
\]
where $\phi_J$ is the normal density, $\Sigma$ is a correlation matrix (for
identifiability), and
\[
A_{ij} = 
\begin{cases}
(-\infty, x_{ij} \beta_j), & y_{ij} = 1 \\
[x_{ij} \beta_j, \infty), & y_{ij} = 0.
\end{cases}
\]
Here $x_{ij}$ is a row of covariates.  I am used to working with the same
covariates for each $\beta_j$, in which case we would drop the $j$ from
$x_{ij}$.  Thus there setup is more general than I am used to.

Equivalently, we can let $y_{ij} = \one (z_{ij} > 0)$, and $B_{ij} = (0,
\infty)$ and then let
\[
P(Y_i = y_i | \beta, \Sigma) = \int_{B_{i1}} \ldots \int_{B_{iJ}} \phi_j(z_i |
x_i \beta, \Sigma).
\]

They sample $z_i$, which is a truncated multivariate normal, by using Geweke.
They sample $\Sigma$ using a Metropolis-Hastings step.

\section{FS and Fussl, 2012}

They use the difference of utilitities representation.  In HH, we had
\[
\begin{cases}
y_i = \one \{ z_i > 0 \} \\
z_i = x_i \beta + \ep_i, \ep_i \sim \text{Lo}.
\end{cases}
\]

I believe in FSF 2010 they extend a similar representation to the binomial case,
which is then used (or extended further) in this paper.

In particular, changing notation slightly, we have
\[
\begin{cases}
\tilde y_i = y_i \cdot 1 \\
y_{ij} = \one \{ y_{ij1}^u > y_{ij0}^u \} \\
y_{ij0}^u = \ep_{ij0}^u \\
y_{ij1}^u = \psi_i + \ep_{ij1}^u, & \psi_i = x_i \beta \\
\ep_{ijk}^u \sim - \log \mcE(1).
\end{cases}
\]
Here I am thinking of $y_i$ being vectorized so that it indicates if there was a
success or failure for $n_i$ components.  An important observation is that we
may aggregate things.  They aggregate and then take logs.  Let $^+$ denote $-\log
\sum_j\exp(- \cdot)$ so that
\[
\begin{cases}
y_{i0}^+ = -\log \sum_{j} e^{-\ep_{ij0}^u} \\
y_{i1}^+ = -\log \sum_{j} e^{-y_{ij1}^u}\\
y_{i1}^+ = -\log \exp(-\psi_i) \sum_{j} e^{-\ep_{ij1}^u} = \psi_i + - \sum_{j}
e^{-\ep_{ij1}^u} \\
\ldots \\
y_{i1}^+ - y_{i0}^+ = \psi_i + \ep_{i1}^+ - \ep_{i0}^+ \\
y_{i}^* = \psi_i + \ep_i^*, & \ep_i^* \sim \text{Type III Logistic}.
\end{cases}
\]
But $\ep_{ik}^+$ is $- \log \text{Gamma}$, the difference of which is type III
logistic.  They use the discrete mixture of normals trick on that distribution.

Given $y^*$ and $r$, the mixture components, we can sample $\beta$, or $\beta_t$
in a dynamic regression.  Given $y^*$ and $\psi$ we can sample $r$.  Thus we
just need to describe how to produce $y^*$.  We can do this marginally given
$\lambda = e^\psi$.

Return to the formulation when we have exponential random variables.  We can
write this as
\[
\begin{cases}
\tilde y_i = \sum y_{ij} \\
y_{ij} = \one \{ \xi_{ij1} < \xi_{ij0} \} \\
\xi_{ij1} = \mcE(1) / \lambda_i \\
\xi_{ij0} = \mcE(1) \\
\xi_{ijk} = \exp (- y_{ijk}^u).
\end{cases}
\]
Now we return to our old friend, the max-trick.  We know that for $x_i \sim
\mcE(\lambda_i)$,
\[
\begin{cases}
p(x_1 | x_1 < x_2) \sim \mcE(rate = \lambda_1 + \lambda_2) \\
p(x_1 | x_1 > x_2) \sim x_2 + \mcE(rate = \lambda_1).
\end{cases}
\]
Of course, this is precisely the information we are conditioning things on.

Actually, we need to joint distribution, which we can get in the following way.
First, recall that (given some conditions)
\[
p(x_1, x_2 | (x_1, x_2) \in A) \propto p(x_1, x_2) \one \{ (x_1, x_2) \in A \}.
\]
(This makes sense if we think in terms of densities.  Also, maybe think in terms
of the canoncial space.)  Then we can show that
\[
p(x_1, x_2 | x_1 > x_2) \propto \lambda_1 e^{- \lambda_1 (x_1 - x_2)} 
(\lambda_2 + \lambda_1) e^{-(\lambda_2 + \lambda_1) x_2} \one \{x_1 > x_2\} \one
\{x_2 > 0 \}.
\]
Thus we can factor this as
\[
p(x_1 | x_2, x_1 > x_2) p(x_2 | x_1 > x_2) \propto p(x_1 \sim \mcE(\lambda_1) + x_2)
p(x_2 \sim \mcE(\lambda_1 + \lambda_2)).
\]

Thus, if $x_1 \sim \mcE(\lambda_1)$ and $x_2 \sim \mcE(\lambda_2)$ and we are
told that $x_1 > x_2$, then we can take a joint draw of $(x_1, x_2 | x_1 > x_2)$
by
\[
x_2 \sim \mcE(\lambda_1 + \lambda_2) \text{ and } 
x_1 \sim x_2 + \mcE(\lambda_1).
\]
Hence we have
\[
\begin{cases}
\xi_{ij1} \sim \mcE(\lambda_i + 1), \xi_{ij0} \sim \xi_{ij1} + \mcE(1), & y_{ij} =
1 \\
\xi_{ij0} \sim \mcE(\lambda_i + 1), \xi_{ij1} \sim \xi_{ij0} + \mcE(\lambda_i), &
y_{ij} = 0.
\end{cases}
\]
Thus to form $(y^*|\lambda,y)$ we have (implicity conditioning on $\lambda$)
\[
(y_{i}^* | y) = - \log \sum_{j} (\xi_{ij1}|y) + -\log \sum_{j} (\xi_{ij0}|y).
\]
The exact order of $y$ does not matter since we scramble that information in the
sum.  Thus for $i =1, \ldots, y_i$ we have
\[
\begin{cases}
\Xi_{j1} \sim \mcE(\lambda_i+1), j=1, \ldots, y_i \\
\Xi_{j0} \sim \Xi_{j1} + \mcE(1), j=1, \ldots, y_i \\
\Xi_{j0} \sim \mcE(\lambda_i+1), j=y_i+1, \ldots, n_i \\
\Xi_{j1} \sim \Xi_{j0} + \mcE(\lambda_i), j=y_i+1, \ldots, n_i.
\end{cases}
\]
We can simplify further by summing and drawing gammas.

That is somewhat confusing, so let me restate things.  Taken from my thesis.
This is based on McFadden:
\[
\begin{cases}
y_i = \sum_{j=1}^n y_{ij} \\
y_{ij} = \one \{z_{ij}^1 > z_{ij}^0 \} \\
z_{ij}^1 = \psi_i + \nu_{ij}^1 \\
z_{ij}^0 = \nu_{ij}^0 \\
\nu_{ij}^u, \nu_{ij}^0 \sim - \log \mcE(1), \; j = 1, \ldots, k;
\end{cases}
\]
where the $z$'s $y$'s are latent.  Consider the map $f$ from $\bbR^n \ra \bbR$:
\[
f(v) = - \log \Big( \sum_{j=1}^k \exp(-v_j) \Big).
\]
Define
\[
\begin{cases}
z_i^* = f( z_{i \cdot}^1) - f(z_{i \cdot}^0) \\
\nu_i^* = f(\nu_{i\cdot}^1) - f(\nu_{i\cdot}^0).
\end{cases}
\]
Then we can collapse $z_{ij}^u = \psi_i + \nu_{ij}^u$ into
\[
z_i^* = \psi_i + \nu_{i}^*, \; \nu_i^* \sim Lo_k.
\]
This gives us the normal mixture.  To see what is happening, consider:
\begin{align*}
f(z_{i \cdot}^1) & = - \log \sum_{j=1}^k \exp(-\psi_i)\exp(-\nu_{ij}^1) \\
& = - \log  \exp(-\psi_i) \sum_{j=1}^k \exp(-\nu_{ij}^1) \\ 
& = \psi_i - \log \Big( \sum_{j=1}^k \mcE_j(1) \Big) \\
& = \psi_i - log \; Ga(k,1) \\
\end{align*}
Thus $\nu_I^*$ is going to be the difference of $- \log \; Ga(k,1)$ random
variates, which must be a definition of Type III logistic.  We take care of this
by normal mixture.  So the question becomes, how do we sample the latent $z$'s.
For that we exploit the exponential distribution---and we do this marginally,
not conditionally on the normal mixture.  This is to say that we assume we have
$y_{ij}$ and $\psi_i$.  We know that
\[
\begin{cases}
y_{ij} = 1 \iff z_{ij}^1 > z_{ij}^0. \\
y_{ij} = 0 \iff z_{ij}^1 <= z_{ij}^0.
\end{cases}
\]
The prior is
\[
e_{ij}^u = \exp(- z_{ij}^u) \sim e^{- \psi_i^u} \mcE(1)
\]
The conditioning information is thus really
\[
\begin{cases}
y_{ij} = 1 \iff e_{ij}^1 < e_{ij}^0 \\
y_{ij} = 0 \iff e_{ij}^1 >= e_{ij}^0.
\end{cases}
\]
From above we know then that
\[
\begin{cases}
y_{ij} = 1 \implies e_{ij}^1 \sim \mcE(1) / (e^{\psi_i} + 1), \; \; 
e_{ij}^0|e_{ij}^1 \sim e_{ij}^1 + \mcE(1) \\
y_{ij} = 0 \implies e_{ij}^0 \sim \mcE(1) / (e^{\psi_i} + 1), \; \; 
e_{ij}^1|e_{ij}^0 \sim e_{ij}^0 + \mcE(1) / e^{\psi_i} \\
\end{cases}
\]
Then
\begin{align*}
f(z_{i\cdot}^1) & = - \log \sum_{j=1}^k \exp(-z_{ij}^1) \\
& = - \log \sum_{j=1}^k e_{ij}^1.
\end{align*}
Similarly
\[
f(z_{i\cdot}^0) = - \log \sum_{j=1}^k e_{ij}^0.
\]
Notice that above the important thing is actually the parameter $\psi_i$.  Let
us call the parameter that matters $\psi_i^1$ and let $\psi_i^0 = 1$.  Then,
really what we have is that
\[
\begin{cases}
y_{ij} = 1 \implies e_{ij}^1 \sim \mcE(1) / (e^{\psi_i^1} + e^{\psi_i^0}), \; \; 
e_{ij}^0|e_{ij}^1 \sim e_{ij}^1 + \mcE(1) / e^{\psi_i^0} \\
y_{ij} = 0 \implies e_{ij}^0 \sim \mcE(1) / (e^{\psi_i} + e^{\psi_i^0}), \; \; 
e_{ij}^1|e_{ij}^0 \sim e_{ij}^0 + \mcE(1) / e^{\psi_i^1} \\
\end{cases}
\]
Then, provided $Ga(0,1) = 0$, which is the case in R, let
\[
\begin{cases}
u_i^{(1)} = Ga(y_i, 1) / (\lambda_i^1 + \lambda_i^0) \\
u_i^{(0|1)} = Ga(n_i - y_i, 1) / \lambda_i^0 \\
v_i^{(1)} = Ga(n_i - y_i, 1) / (\lambda_i^1 + \lambda_i^0) \\
v_i^{(1|0)} = Ga(y_i, 1) / \lambda_i^1.
\end{cases}
\]
Then
\[
\begin{cases}
\sum_{j=1}^k (e_{ij}^1|y_{ij}) = u_i^{(1)} + (v_i^{(0)} + v_i^{(1|0)}) \\
\sum_{j=1}^k (e_{ij}^0|y_{ij}) = v_i^{(0)} + (u_i^{(1)} + u_i^{(0|1)}) 
\end{cases}
\]
But further, if we let
\[
w_i = u_i^{(1)} + v_i^{(1)} = Ga(n_i, 1) / (\lambda_i^1 + \lambda_i^0)
\]
then that is
\[
\begin{cases}
\sum_{j=1}^k (e_{ij}^1|y_{ij}) = w_i + v_i^{(1|0)} \\
\sum_{j=1}^k (e_{ij}^0|y_{ij}) = w_i + u_i^{(0|1)}.
\end{cases}
\]
This gives us something like Fussl's code where
\[
\begin{cases}
w_i = \text{rgamma}(n_i,1) / (\lambda_i^1 + \lambda_i^0) \\
u_i = \text{rgamma}(n_i-y_i, 1) / \lambda_i^0 \\
v_i = \text{rgamma}(y_i, 1) / \lambda_i^1
\end{cases}
\]
and
\begin{align*}
z_i^*|y_i & = - \log \sum_{j=1}^k (e_{ij}^1|y_{ij}) - - \log \sum_{j=1}^k
(e_{ij}^0|y_{ij}) \\
& = - \log(w_i + v_i) + \log(w_i + u_i),
\end{align*}
where, to reiterate, $Ga(0, 1) = 0$.

Thus, note to self, insofar as the CUDA code goes, I need to make sure that the
gamma sampler returns 0 when the shape parameter is 0!  In fact, it might make
some sense to make a custom CUDA routine just to sample the $z_i^*|y_i$ since
there is overhead, I believe to making any CUDA calls.  We could take three
DMONs as the objects of the class and set them up in the usual fashion.  We
could then create a custom call to handle that makes use of the space set aside
by these classes to do the actual calculations.

Returning to the regression coefficient.  We have
\begin{align*}
z_i^* & = \psi_i + \ep_i, \; \ep_i \sim N(0, v_{n_i,r_i}) \\
& = x_i \beta + \ep_i, \; \ep_i \sim N(0, v_{n_i,r_i}) ,
\end{align*}
where $n_i$ denotes the number of trials and $r_i$ denotes the specific mixture
component.  In vector notation, the exponent will be
\[
(z^* - X \beta)' P (z^* - X \beta) = \beta' X'PX \beta - 2 \beta' X'P z^*.
\]
Thus, $b = X'Pz^*$, and we will have to set that anew after every draw of
$z^*|y$.

To speed things up, I need to do the following.  First, sample $(z_i^*,
V_i)$ jointly.  One can decompose the joint draw as
\[
p(\{z_i^*\} | \{y_i\}) \prod_{i=1}^N p(V_i = v_{n_i,r_i} | z_i^*)
\]

From Nvidia profiler guide: \emph{Memory optimizations are the most important
  area for performance.}

I believe we want $n$, $y$, and $\psi$ in their own vectors, since for parallel
and GPU's we will grab them in chunks.
\begin{enumerate}
\item To do this, first set $\lambda_i^{(1)} = \psi_i$ and $\lambda_i^0 = 1$.

\item For each $i$, draw ($w_i$, $u_i$, and $v_i$ can all be local).
\[
\begin{cases}
w_i = \text{rgamma}(n_i,1) / (\lambda_i^1 + \lambda_i^0) \\
u_i = \text{rgamma}(n_i-y_i, 1) / \lambda_i^0 \\
v_i = \text{rgamma}(y_i, 1) / \lambda_i^1
\end{cases}
\]
and set
\begin{align*}
z_i^*|y_i 
& = - \log(w_i + v_i) + \log(w_i + u_i),
\end{align*}

\end{enumerate}

\section{Migon etal 2005}

Dynamic Models, from the Handbook of Statistics vol. 25.

Really, this article is a review of other work.

\begin{outline}

\1 Review of dynamic linear models

\1 I liked their ``Practical aspects of Bayesian forecasting'' section

  \2 Variance law: you can model $V_t$.

  \2 Discount factor: you can let $W_t$ evolve.
  
  \2 Missing observations are easily handled.
  
  \2 You can do retrospective analysis.
  
  \2 Easy to monitor and intervene.

\1 They have a section on Sequential Monte Carlo.  I think we can avoid that
since we want to produce exact posterior distributions.

\1 MCMC to sample states.

\2 They mention the normal DLM.  FFBS is one option.  They also mention doing a
joint draw of the states by using some sparse decomposition routine for the
precision matrix.

\2 Gammerman (1998) suggests a proposal for the innovations $\omega_t$.

\2 Shephard and Pitt (1997) and Knorr-Held (1999) supposedly have some sort of
block proposals.

\2 And that is where they stop.

\end{outline}

\section{Gamerman 1997}

Sampling from the posterior distribution in generalized linear mixed models

Setup:
\[
\begin{cases}
\eta_i = x_i' \beta + z_i' \gamma \\
\gamma \sim N(0, \Sigma) \\
\Sigma \sim IW \\
\beta \sim N(a, R).
\end{cases}
\]

Consider a generalized linear model.  Check out Wedderburn, 1974 below if you do
not remember this.  We can use quasi-likelihoods to estimate $\beta$.  In
particular, we can come up with can interprate Newton-Raphson as iterative least
squares by letting
\[
\begin{cases}
\tilde y_i(\beta) = \eta_i + (y_i - \mu_i) g'(\mu_i) \\
W_i(\beta) = 1 / (b''(\theta_i) g'(\mu_i)^2)
\end{cases}
\]
where $\eta_i = x_i \beta$, $\eta = g(\mu)$, and the exponential family has the
form
\[
x \sim h(x) \exp \Big( \frac{x \theta - b(\beta)}{\phi_i} \Big).
\]
Then we can iteratively solve for $\beta^*$ as the least squares estimate of
\[
\tilde y(\beta) = X \beta^* + \ep, \; \ep \sim N(0, W^{-1}(\beta)).
\]
Incorporating a prior into the likelihood is equivalent to finding the posterior
mode $\beta^*$ for the linear model above with a $\beta^* \sim N(a, R)$ prior.

Gamerman suggest combining a Newton Raphson step with a Metropolis step. Suppose
one has drawn $\beta^{(t-1}$.  Now, one can use that $\beta$ to construct the
new psuedo-data and psuedo-weights, $\tilde y(\beta^{(t-1)}$ and
$W(\beta^{(t-1)}$.  Then one can calculate the posterior moments $m^{(t)}$ and
$C^{(t)}$.  Then one can then propose $\beta^* \sim N(m^{(t)}, C^{(t)})$ and
accept or reject to get $\beta^*{(t)}$.

I think it is illuminating to go back to the orignal interpretation.  One is
standing at $\beta^{(t-1)}$.  One wants to generate a proposal.  Instead of
doing, for instance, independence-Metropolis, the idea is to generate a proposal
centered at $\beta^{(t-1)}$.  So you do the Taylor expansion at that point to
generate a normal proposal.  This is the normal proposal described above.  So
really, this is like a random walk Metropolis with a smart proposal.

One could also move towards an independence Metropolis sampler.  Instead of
basing the next proposal on $\beta^{(t-1)}$, we could base the next proposal on
$m^{(t-1)}$.  In that case we could be moving towards the posterior mode and the
Hessian at the posterior mode.  Along the way we would be sampling $\beta$'s.
One could presumably stop picking new $m$'s and $C$'s once $m$ stopped moving
around.

Gamerman suggests blocking for the mixed model, which reduces to two iteratively
reweighted steps and an extra step to draw $\Sigma$.  One coulde, in fact,
jointly sample $\beta$ and $\gamma$, thought this might not (automatically) take
advantage of the sparsity present in the ``joint'' design matrix.  Gamerman's
suggestion is:
\begin{itemize}
\item Sample $(\beta | \gamma, \Sigma)$ using the normal approxmation centered
  at $\beta^{(t-1)}$.  This is weighted least squares plus a metropolis step.
\item Sample $(\gamma | \beta, \Sigma)$ using the normal approximation centered
  at $\gamma^{(t-1)}$.  This is weighted least squares plus a metropolis step.
\item Sample $(\Sigma | \beta, \gamma) = (\Sigma | \gamma)$, which is conjugate
  given $\gamma$.
\end{itemize}
This will involve inverting matrices in the first and second steps at every
iteration of the MCMC, which presumably could be slow.

\section{Gamerman 1998}

Markov Chain Monte Carlo for Dynamic Generalized Linear Models

In Wedderburn (1974) one sees that Netwon-Raphson can be viewed as iteratively
reweighted least squares when working within exponential families.  This can be
extended to the case in which one has a prior distribution on $\beta$, which was
evidently shown by M. West (1985).  Evidently, you can take this one step
further to dynamic linear models, which was done by Singh \& Roberts (1992).

My guess is the following.  You can do the same analysis as in Wedderburn,
excpet that instead of looking at the derivative of $\beta_i$, you need to
consider $\beta_{it}$.  That will not change much in the log-likelihood, except
as to eliminate the summation.  The Hessian will be
\[
\frac{1}{V_{\mu_t}} \Big( \frac{d\mu_t}{d Y_t} \Big)^2 x_{it} x_{jt} 
\]
and the gradient will be
\[
\frac{r_t}{V(\mu_t)} \frac{d \mu_t}{d Y_t} x_{it}.
\]
But this is a vector (matrix) in $i$ (and $j$) \emph{and} $t$.  Notice that the
Hessian is ``block diagonal in $t$.''  Were there no ``prior'' this would be a
rather useless model.  The prior ties together the $\beta_{it}$'s.  Suppose $a$
is the ``prior'' mean and $P$ is the ``prior'' precision, in the sense that $a$
and $P$ describe the mean and precision for a, for instnace, AR(1) process.  In
that case one can view Newton-Raphson as a DLM where one calculates the
posterior mean at each iteration, which one can do via retrospective analysis.
See Harrison and West p. 113.

There are a few possibilities: one could take a joint draw from the Laplace
approximation via FFBS and then do MH, but this has low acceptance rates; one
could do things componentwise for $\{\beta_t\}$, i.e. one would sample
$p(\beta_t | \beta_{t-1}, \beta_{t+1}, y_t)$ for $t=1, \ldots, T$, but this
introduces a ton of autocorrelation.  I believe Gamerman suggests sampling the
innovations $\omega_t$ component wise instead (it seems).  Evidently, Shephard
and Pitt use ``random block sampling'' to use the FFBS framework to get decent
acceptance rates and reduce the autocorrelation between samples.  Presumably,
they FFBS+MH in blocks.  It appears that Gamerman does not test against Shephard
and Pitt, 1997.  Evidently, this method works well against the others.

I think one needs to make two distinctions here.  There are random-walk-like
proposals and moving-to-mode like proposals.  Whenever you take a Laplace
approximation, you must decide where it should be centered.  You will have the
option to center it at the previously calculated approximate mode or at the
previously drawn $\beta$.  I am thinking of random-walk-like proposals as
proposals based upon approximations centered at the previous draw.  I am
thinking of moving-to-mode like proposals being approximations centered at the
previous ``mode.''  I believe Gamerman suggests generating proposals centered at
the previous draw.

\begin{outline}

\1 It appears that the competition mentioned in this paper is

  \2 Fahrmeir et al. (1992), rejection sampling

  \2 Carlin and Polson (1992), use latent variables + Gibbs.

  \2 Shephard and Pitt (1997), use FFBS+MH in blocks.

  \2 Carlin et al. (1992), component wise in $\beta_t$.

  with Gelfand and Smith.  Hierarchical Bayesian Analysis of Changepoint
  Problems.  Applied Statistics, 42.

  \2 Gamerman, use componenent wise MH for distribuances.  

\end{outline}

\section{Geweke and Tanizaki, 2001}

They have a more comprehensive introduction than Ravines et al 2006.  To
paraphrase/quote:
\begin{outline}

\1 Kitigawa (1987) and Kramer and Serenson (1988) proposed the nonlinear
  filter and smoother using numerical integration.

\1 Carlin et al. (1992) and Carter and Kohn (1994, 1996) use Gibbs sampling.

\1 Gordon et al. (1993), Kitigawa (1996), and Kitagawa and Gersch (1996) propose
filterting and smoothign using resampling.  This takes an extremely long time
computationally.

\1 Tanizaki (1996, 1999), Tanizaki and Mariano (1998) and Mariano Tanizaki
(2000) proposed nonlinear filtering and smoothign using rejection sampling.
This can have extremely low acceptance rates.

\1 Geweke and Tanizaki (1999) is a non-normal smoother from a non-Bayesian point
of view.  Presumably this paper is an extension of that.

\end{outline}

They consider the general Markovian state-space model, which is not limited by
Gaussianity or linearity, just $p(y_t | x_t)$ and $p(x_t | x_{t-1})$ as the
distributions (with suppressed parameters) that guide the evolution and
measurements in the system.

See the bottom of page 154 and top of 155 and the subsequent paragraph.  They
are proposing a componenent wise Gibbs scheme.  They suggest using a second
order approximation to the log-kernel, the kernel being $p(\alpha_t | y_t,
\alpha_{t-1}, \alpha_{t+1})$ where $\alpha_t$ is the state.  I believe they
suggest centering this proposal around the previous proposal.  In other words,
they propose a Laplace approximation.  The consider cases in which the density
is not locally concave.

\section{Shephard and Pitt, 1997}

Title: Likelihood analysis of non-Gaussian measurement time series

As noted in the notes from Gamerman (1998), the goal here is to block and use
the FFBS+MH with a suitable approximation.  So long as the blocks aren't too
big, this should work okay.

\section{Carter and Kohn, 1994}

Title: On Gibbs Sampling and State Space Models.

They suggested the FFBS in this paper concurrently with FS.  They also discuss
using mixture of normals for the innovation and observation disturbances a la
Carlin et al 1992.  As we know, this is all doable via Gibbs sampling.

\section{Carter and Kohn, 1996}

Suggest letting parameters $F_t$, $G_t$, $V_t$, $W_t$ be determined by some
latent indicators $\gamma_t$ and letting $\gamma_t$ evolve as a Markov chain (I
think).

\section{Carlin, Polson, Stoffer, 1992}

Title: A Monte Carlo approach to non-normal and nonlinear state space modeling.

DLM:
\[
\begin{cases}
y_t = H_t x_t + v_t, & v_t \sim N(0, \Upsilon) \\
x_t = G_t x_{t-1} + u_t, & u_t \sim N(0, \Sigma).
\end{cases}
\]
Their first suggestion: use normal mixtures so that the innovation and
observation distribances are non-normal.  In partiuclar, if one has
\[
\begin{cases}
y_t = H_t x_t + v_t, & v_t \sim N(0, \omega_t \Upsilon) \\
x_t = G_t x_{t-1} + u_t, & u_t \sim N(0, \lambda_t \Sigma)
\end{cases}
\]
then one can arrive at a variety of different forms for the marginal
distributions $p(x_t | x_{t-1}, \Sigma)$ and $p(y_t | \Upsilon)$ (supressing
``parameters'').  We can write lots of stuff as normal mixtures.

I believe, if you look back at some of the work of Harrison, you will find that
he employs something similar to this idea, though it is for discrete mixtures I
believe.

They then go on to discuss componenent wise Gibbs sampler.  This is pre FS and
Carter and Kohn.

\section{Wedderburn, 1974}

Quasi-likelihood functions, generalized linear models, and the Gauss-Newton method

This is a great paper.

I believe this work comes from studying log-likelihoods.  At the end of the day,
people are ineterested in maximizing likelihoods.  In that case, one can turn to
Newton-Raphson for maximization.  That, in turn, can often be viewed as
interatively reweighted least squares, which I think may be synonymous with
Gauss-Newton.  Sometimes people do not want to use the the Hessian, so instead
they use the Fischer information matrix which is the expectation of the Hessian,
I believe.  That will often still converge to a (local) maximum.

I think it is often the case that we are observing i.i.d. data at some sort of
conditional mean; it may be the case that the conditional mean also impacts the
variance.  In that case our log likelihood takes the form
\[
\ell(\beta | y) = \sum_{i=1}^n f(\mu_i = x_i' \beta).
\]
The partial of $\ell$ is
\[
\graddel{\ell}{\beta_i}[h_i]:= \sum_{k=1}^n \graddel{f}{\mu_k}
\graddel{\mu_k}{\beta_i} h_i.
\]
Thus the gradient is
\[
G(\beta)[h] = \sum_{k=1}^n \graddel{f}{\mu_k}
\graddel{\mu_k}{\beta} h.
\]
We are implicitly evaluating $\graddel{f}{\mu_i}$ and $\graddel{\mu_i}{\beta}$ in
the summation.  Taking the derivative of the partial we have
\[
\hessdel{\ell}{\beta_j}{\beta_i}[h_i^{(1)}, h_j^{(2)}]:= \sum_{k=1}^n
\hessdel{f}{\mu_k}{\mu_k} \graddel{\mu_k}{\beta_i} h_i^{(1)}
\graddel{\mu_k}{\beta_j} h_j^{(2)} + \graddel{f}{\mu_k}
\hessdel{\mu_k}{\beta_j}{\beta_i} h_i^{(1)} h_j^{(2)}.
\]
Thus, the Hessian of $\ell$ is
\[
H(\beta)[h_1, h_2] := 
\sum_{i=1}^n h_2' 
\graddel{\mu_i}{\beta}' \hessdel{f}{\mu_i}{\mu_i}\graddel{\mu}{\beta} h_1 
+ \graddel{f}{\mu_i} h_2' \hessdel{\mu_i}{\beta}{\beta} h_1
\]
where again we are implicitly evaluating the Hessian of $f$ in $\mu$ at $\mu_i =
x_i \beta$.

Once we have the gradient and the Hessian then we can use Newton-Raphson,
i.e. succesive second order approximations to the curve to get to a local
maximum.  As mentioned earlier, this may be interpreted as iteratively
reweighted least squares.  

There are several properties of likelihoods, which I still have to learn.  In
any event, it is these properties that quasi-likelihoods possess.  Of course, as
tools for frequentist estimation, the only thing that matters is that the
quantity one arrives at is consistent and maybe some sort of limit theorem for
the asympototic distribution.

The properties are
\begin{itemize}
\item 
  \(
  \bbE \Big( \graddel{K}{\mu} \Big) = 0;
  \)
  
\item
  \(
  \bbE \Big( \graddel{K}{\beta_i} \Big) = 0;
  \)

\item 
  \(
  \bbE \Big( \graddel{K}{\mu} \Big)^2 = - \bbE \Big( \frac{\del^2 K}{\del \mu^2}
  \Big) = \frac{1}{V(\mu)}.
  \)

\item 
  \(
  \bbE \Big( \graddel{K}{\beta_i} \graddel{K}{\beta_j} \Big)
  = - \bbE \Big( \hessdel{K}{\beta_i}{\beta_j} \Big) 
  = \frac{1}{V(\mu)} \graddel{\mu}{\beta_i} \graddel{\mu}{\beta_j}.
  \)
\end{itemize}
I believe one can equivalently require that a quasi-likelhood have the form
\[
\frac{\del K(z_i, \mu_i)}{\del \mu_i} = \frac{z_i - \mu_i}{V(\mu_i)}.
\]
One can certainly start from here and then arrive at the 4 items above, since
that is what Wedderburn does.

Further, I believe those properties are going to ensure that there is some
maximum of the quasilikelihood.  The quasi-likelihood is defined in terms of
$(z_i, \mu_i)$, which are the data and the conditional mean.  We know that $\del
K / \del \beta_i$ has mean zero.  Wedderburn uses the notation $S$ to denote the
summation operator.  Thus $S(K)$ will act like the log-likelihood.  Let $u =
\del K / \del \beta$ and let $H = \del^2 S(K) / \del \beta_i \del \beta_j$, then
$S(u)$ has expectation zero and dispersion $D = - \bbE(H)$.  Now if we follow a
method of moments type argument, we want to pick $\beta$ so that $S(u)$ is zero
for the observed data $z_i$.  We could also think in terms of maximizing the
quasi-likelihood: we want $S(u)$ to be zero because that is the first order
condition for a critical point.  In either case, we are going to move via
Newton-Raphson to some critical point $\beta^*$.  At the critical point we have
$S(u(\beta)) = S(u(\beta)) - S(u(\beta^*)) \simeq H(\beta - \beta^*)$.  We can
approximate $H$ by $D$, which I can see being useful back in the day when one
would not want to recalculate a bunch of (potentially large) matrices.

Connection to Gauss-Newton: Wedderburn notes the following.  Let $v_i$ denote
$\del \mu / \del \beta_i$ and $r_i = z_i - \mu_i$.  Then
\[
\graddel{S(K)}{\beta_i} = S \Big\{ \frac{z_k - \mu_k}{V(\mu_k)} \frac{\del
  \mu_k}{ \del \beta_i} \Big\} = S \Big\{ \frac{r \odot v_i}{\odot V(\mu)} \Big\}.
\]
Further
\[
- \bbE \Big\{ \hessdel{S(K)}{\beta_i}{\beta_j} \Big\} = S \Big\{ \frac{v_i
  \odot v_j}{\odot V(\mu)} \Big\}.
\]
Here, I am using the notation $\odot V(\mu)$ to emphasize that $V(\mu)$ is a
vector and that the division above is component-wise.  Now we can do
Newton-Raphson using these two quantities.  Wedderburn ties this Newton-Raphson
to iteratively weighted least squares in Theorem 4 on p. 444.

Consider Newton Raphson for a moment.  You have a gradient $G(\beta)$ and a
Hessian $H(\beta)$ at the current value of $\beta$ of $F(\beta)$.  The maximum
of the second order approximation is at $-H^{-1} G$, as one can see by
completing the square or calculating the first derivative of
\[
F(\beta + x) \simeq \frac{1}{2} x' H x + G x + F(\beta),
\]
in which case
\[
Hx + G = 0 \implies x = - H^{-1} G.
\]
Thus we have
\[
\delta \beta = - H(\beta)^{-1} G(\beta)
\]
and
\[
\beta^* = \beta - H(\beta)^{-1} G(\beta).
\]

Wedderburn notes that when the conditional mean is determined by $f(\mu_k) =
x_k' \beta = Y_k$, which we can think of saying that in general $\mu$ is a
function of $Y$ and $\mu_k = \mu(Y_k)$, then we have that (for a single
observation)
\[
v_i = \graddel{\mu}{\beta_i}(\beta_i) = \graddel{\mu}{Y} x_i .
\]
Hence the update for $\beta$ is determined by
\[
\sum_{jk} \frac{1}{V(\mu_k)} \Big(\graddel{\mu_k}{Y_k}\Big)^2 x_{ik} x_{jk} \delta
\beta_j
= \sum_{k} \frac{r_k}{V(\mu_k)}\graddel{\mu_k}{Y_k} x_{ik}
\]
where $\mu_k = \mu(x_k' \beta)$ and $\graddel{\mu_k}{Y_k} =
\graddel{\mu}{Y}(x_k' \beta)$ and $x_k$ refers to the vector of predictors for
observation $x_k$.  The $i$ and $j$th indices refer to the $i$ and $j$th
predictors.

Note that 
\[
\sum_{jk} \frac{1}{V(\mu_k)} \Big(\graddel{\mu_k}{Y_k}\Big)^2 x_{ik} x_{jk}
\beta_j = 
\sum_{k} \frac{1}{V(\mu_k)} \Big(\graddel{\mu_k}{Y_k}\Big)^2 x_{ik} Y_k.
\]

Thus the update $\beta^* = \beta + \del \beta$ can be written as
\[
\sum_{jk} \frac{1}{V(\mu_k)} \Big(\graddel{\mu_k}{Y_k}\Big)^2 x_{ik} x_{jk} 
\beta_j^*
=
\sum_{k} \frac{1}{V(\mu_k)}\Big(\graddel{\mu_k}{Y_k} \Big)^2  x_{ik} (Y_k + r_{k} 
\frac{\del Y_k}{\del \mu_k}).
\]
Putting this in matrix notation, let $D =
\frac{1}{V(\mu_k)}\Big(\graddel{\mu_k}{Y_k} \Big)^2$ and let $X_{ik} = x_{ki}$.
Then
\[
X' D X \beta^* = D X' \tilde Y
\]
where
\[
\tilde Y_k = Y_k + r_k \graddel{Y_k}{\mu_k}
\]
and $\tilde Y$ and $D$ are functions of the current value of $\beta$.  Thus we
see that, indeed, the updates, $\beta^*$ can be seen as least squares solutions
given the ``current'' response $\tilde Y$ and the ``current'' weights $D$.  In
particular, we can view the update $\beta^*$ as the MLE or weighted least
squares estimate of
\[
\tilde Y(\beta) = X \beta^* + \ep, \; \ep \sim N(0, D^{-1}(\beta)).
\]
Putting this all together, we have
\[
\begin{cases}
  r_k = z_k - \mu_k \\
  \mu_k = g(Y_k), \; g = f^{-1} \\
  Y_k = x_k' \beta \\
  \graddel{Y}{\mu}(\mu) = f'(\mu) = 1/g'(f(\mu)) \\
  \graddel{Y_k}{\mu_k} = 1/g'(Y_k) = f'(\mu_k) \\
  D_{ii} = \frac{1}{V(\mu_k)}\Big(\graddel{\mu_k}{Y_k} \Big)^2 \\
  \graddel{\mu_k}{Y_k} = g'(Y_k) = 1/f'(\mu_k).
\end{cases}
\]

One advantage of quasi-likelihoods is that you can include over-dispersion.
Thus in Poisson regression, for instance, you can include a scale parameter and
typographically replace $V(\mu_k)$ with $\sigma^2 V(\mu_k)$ everywhere above.

\section{Green, 1984}

Iteratively Reweighted Least Squares for Maximum Likelihood Estmation, and some
Robust and Resistant Alternatives.


\section{Miscellaneous}

\begin{outline}

\1 Talking with Larry Carin: he said that logit is preferable to probit because
you can sample $p$ (the probability) directly whereas within probit you can only
easily sample 1,0.  I don't know what he meant.

\1 Think about Poisson Binomial

\1 Coal mining data: \url{http://people.reed.edu/~jones/141/Coal.html}.

\end{outline}

\section{Things to look up:}

\begin{outline}

\1 Peskun ordering (p. 153 Holmes and Held, 2006)

  \2 After looking that up revisit that the aforementioned section in Holmes and
  Held.

\1 Rao-Blackwellization.  Look up in Gelfand and Smith, 1990.

\2 Rao-Blackwellization refers to conditioning on a sufficient statistic to
reduce variance of estimate.  It relies upon identity
\[
\Var(X) = \Var(\bbE[X|Y]) + \bbE[\Var(X|Y)].
\]
You can find a discussion of this in Berger and Casella.  First, $\bbE[X|Y]$ is
an unbiased estimator as well and it has small variance than $X$.  Second, and
more subtle, is that we need $Y$ to be a sufficient statistic.  If it is not a
sufficient statistic, then the esitmator $\bbE[X|Y]$ may depend upon the
underlying parameter $\theta$, which isn't helpful since we don't know $\theta$.
In other words, when $Y$ is sufficient then $p(x | y, \theta) = p(x | y)$, which
may not otherwise be the case.


\1 What is a quantile-quantile (QQ?) plot good for?

\1 Mixed effects models.

\1 Check out the book Generalized Linear Models by McCullagh and Nelder, 1999.

\end{outline}

% If you have a bibliography.
% The file withe bibliography is name.bib.
\bibliography{bayeslogit}{}
\bibliographystyle{abbrvnat}

\end{document}
