\documentclass[11pt]{article}

\input{commands}

\usepackage{natbib}

\newcommand{\Polya}{P\'{o}lya}
\newcommand{\PG}{\text{PG}}
\newcommand{\Pois}{\text{Pois}}
\newcommand{\Ga}{\text{Ga}}
\newcommand{\NB}{\text{NB}}
\newcommand{\floor}[1]{\lfloor #1 \rfloor}
\newcommand{\eqd}{\,{\buildrel d \over =}\,}
\newcommand{\KS}{\text{KS}}

\newcommand{\point}{\noindent $\bullet$ }

% Page Layout
\setlength{\oddsidemargin}{0.0in}
\setlength{\textwidth}{6.5in}
\setlength{\textheight}{8in}
%\parindent 0in
%\parskip 12pt

% Set Fancy Style
%\pagestyle{fancy}

%\lhead{Left Header}
%\rhead{Right Header}

\title{Dynamic Generalized Linear Models using \Polya-Gamma augmentation}
\author{Carlos M. Carvalho, James G. Scott, Liang Sun, Jesse Windle}

\begin{document}

\maketitle
\tableofcontents

\newpage

\section{Introduction}

In this paper, we show how the \Polya-Gamma data augmentation technique of
\cite{polson-etal-2012} may be used for posterior inference in dynamic
generalized linear models with logistic likelihoods.  Further, we show that this
method outperforms several competitors.

Generalized linear models extend linear models by accomodating non-normal
responses \citep{mccullagh-nelder-1989}.  In a generalized linear model (GLM)
the response $y_t \sim P(\psi_t)$ depends on $\psi_t$ in a possibly non-linear
way while $\psi_t$ itself is a linear combination of predictors, $x_t' \beta$.
Extensions to the dynamic case are straightforward via a dynamic regression:
$\psi_t = x_t' \beta_t$, where one must specify the dynamics of $\beta_t$ to
complete the model.  Unlike Gaussian, linear models, most likelihoods found in
generalized linear models do not lead to convenient posterior distributions for
$\beta$ or $\{\beta_t\}$.  Thus, when generating posterior samples one must
appeal to Metropolis-Hastings, Gibbs sampling with data augmentation, or some
other MCMC method.  

The challenge of generating posterior samples is exacerbated for dynamic models
since there are many more parameters, or states rather, to estimate, which makes
direct extensions of Metropolis-Hastings samplers from the static to dynamic
case difficult.  This is the case for GLMs with logistic likelihoods, a subclass
that has observation densities of the form
\[
p(y | \psi) \propto h(y) \prod_{i=1}^n
\frac{(e^{\psi_i})^{a_i(y)}}{(1+e^{\psi_i})^{b_i(y)}}
\]
and for which \Polya-Gamma data augmentation is applicable.  Such likelihoods
arise when modeling proportions or counts.  For instance, binomial logistic
regression and negative binomial regression may be written in the form above.
These two models alone are useful in a wide variety of applications.  The
dynamic versions of these models are used in economics [McFadden], epidemiology
[cite Lauren], ecology [cite Lauren], and neuroscience [cite Jonathan and Larry]
amongst others.  Hence, it is important to know the most efficient methods for
generating posterior samples for such models.

This paper examines the relative merits of the three approaches for posterior
inference in dynamic generalized linear models (GDLM) with logistic likelihoods:
linear Bayes with conjugate updating and a Metroplis-Hastings step
\citep{ravines-etal-2006}, a discrete mixture of normals approximation
\citep{fruhwirth-schnatter-etal-2009, fussl-etal-2013}, and the \Polya-Gamma
data augmentation scheme.  We show that the \Polya-Gamma technique has superior
effective sample sizes and often superior effective sampling rates compared to
the other methods.

The outline of the paper is as follows: Section 2 reviews other methods of
inference for dynamic generalized linear models; Section 3 shows how one may use
the \Polya-Gamma data augmentation technique in the dynamic setting; Section 4
presents the benchmarking results; Section 5 concludes.

\section{Previous Efforts}

Bayesian inference for dynamic generalized linear models dates back to at least
\cite{west-etal-1985} who used conjugate updating with backwards sampling by
linear Bayes (CUBS) to sample the dynamic regression coefficients of DGLMs when
the observation $(y_i | \psi_i)$ comes from an exponential family; but their
method is only approximate.  Much effort has been devoted to developing exact
posterior samplers, though none has proved to be completely satisfactory.  A
primary goal of any such sampler is to sample states jointly, like the filter
forward backwards sampler (FFBS) of \cite{fruhwirth-schnatter-1994} and
\cite{carter-kohn-1994}, since jointly sampling states tends to result in less
autocorrelation than sampling the states component-wise, a technique suggested
by \cite{carlin-etal-1992} prior to the advent of the advent of the FFBS.
However, the FFBS procedure requires conditionally linear state-space evolution
equations and conditionally linear, Gaussian observation equations.  Absent
these assumptions, as is the case with exponential families, the machinery of
the FFBS breaks down.  To resurrect the FFBS one may approximate the posterior
using a dynamic linear model (DLM) and then accept or reject using
Metropolis-Hastings. or one may use data augmentation so that, conditinoally,
the observations and states are generated by a DLM, though neither method is
gaurenteed to work well.  Several authors have examined methods that abandon the
FFBS sampler altogether.

\cite{geweke-tanizaki-2001} highlight the various works of Kitigawa, Tanizaki,
and Mariano, amongst others, and their efforts to filter, smooth, or simulate
states from non-linear and non-Gaussian state-space models using numerical
integration, resampling, or rejection sampling.  However, each of the approaches
they review is flawed: numerical integration does not work well for any but the
simplest settings, sampling marginally smoothed states using sequential methods
is time consuming, and rejection sampling may have poor acceptance
probabilities.  None of the methods cited by Geweke and Tanizaki are useful for
generating posterior samples of the states jointly, an extremely desirable
property.  Their solution is to sample the states component-wise using a Laplace
approximation and a Metropolis-Hastings step, a technique that as noted above
increases autocorrelation between samples.

\cite{gamerman-1998} discusses the same idea when the observation equation comes
from an exponential family and the evolution of the states is linear and
Gaussian.  Again, for either exponential families or more general observation
equations, one is bedeviled by the autocorrelation induced by sampling the
states component-wise.  Gamerman notes that one may use a global Laplace
approximation to generate a joint proposal for the states; however, such a
proposal may have low acceptance probabilities.  Gamerman's solution is to
transform the problem so that one samples the innovation variances componenent
wise using a Laplace approximation and Metropolis-Hastings, arguing that that
coordinate system possesses less intrincinc correlation.  But this approach is
more computationally intensize since one must transform the proposals back to
the original coordinate system at each iteration to evaluate Metropolis-Hastings
acceptance probability.

\cite{shephard-pitt-1997} attempt to strike a balance between the
autocorrelation of consecutive samples and the acceptance probabilities of
proposed samples by drawing blocks of states.  Sampling in blocks reduces
autocorrelation; restraining the size of the blocks ensures a reasonable
Metropolis-Hastings acceptance probability.  However, their method suffers too
since it cannot take a joint draw of the hidden states.

More recently, techniques have emerged which do generate joint draws of the
states.  \cite{ravines-etal-2006} built upon \cite{west-etal-1985} by adding a
Metropolis-Hastings step to sample the states exactly.  Though this at first
would seem like a poor choice due to high-dimensionality encountered in time
series, they find that, in fact, the technique results in reasonable acceptance
rates unlike the global Lapalce approximation mentioned, which can be seen in
the light of interatively weighted least squares \citep{wedderburn-1974}.  The
fact that conjugate update improves the Metropoli-Hastings proposal enough to
allow for ``efficient'' joint draw is somewhat surprising.

Fr\"{u}wirth-Schnatter and her colleagues have explored data augmentation
techniques that rely upon discrete mixtures of normals to arrive at
conditionally Gaussian posteriors in a variety of settings including binomial
logistic regression and multinomial regression
\citep{fruhwirth-schnatter-fruhwirth-2007, fruhwirth-schnatter-fruhwirth-2010,
  fussl-etal-2013}, Poisson regression \citep{fruhwirth-schnatter-wagner-2006,
  fruhwirth-schnatter-etal-2009}, and negative binomial regression for count
data \citep{fruhwirth-schnatter-etal-2009}.  All of these techniques may be used
in static and dynamic regressions.  While these methods work well, several rely
upon precomputing large tables of weights, means, and variances, to approximate
an entire family of distributions.  Further all of the discrete mixture of
normal techniques make use of at least three layers of auxiliary variables.  One
would prefer to avoid many layers of latents since this inhibit traversing the
posterior landscape.

Posterior inference for binomial logistic regression in
\cite{fruhwirth-schnatter-fruhwirth-2007} is based upon the latent utilities
interpretation of \cite{mcfadden-1974}.  Later, in a discrete mixture of normals
approach based upon \cite{holmes-held-2006} is found to be superior
\citep{fruhwirth-schnatter-fruhwirth-2010}.  This approximation outperforms
\cite{holmes-held-2006} as well since due to its computation efficiency.  The
2010 paper includes an extensive comparison of various data augmentation and
Metropolis-Hastings methods in the static case.  Most recently,
\cite{fussl-etal-2013} put forth another generation of posterior samplers for
binomial logistic regression using discrete mixtures of normals that outperforms
its ancestors.  Much of this work can be traced back the
\cite{albert-chib-1993}, which provides a data augmentation approach to probit
regression and which has a dynamic analog.  We limit our comparison below to
\cite{fussl-etal-2013} since it appears to be the best choice for dynamic
binomial logistic regression within Fr\"{u}wirth-Schnatter school.

\section{\Polya-Gamma Data Augmentation}

The \Polya-Gamma data augmentation technique has a single layer of latent
variables that yields conditionally Gaussian posterior distributions when
working with logistic likelihoods.

Suppose that the data generating distribution $(y_t | \psi_t)$ has a conditional
distribution of the form
\[
p(y_t | \psi_t) = c(y_t) \frac{(e^{\psi_t})^{a_t}}{(1+e^{\psi_t})^{b_t}}
\]
and that $a_t$ and $b_t$ are functions of the data, but not $\beta_t$.  By
recognizing that
\[
\cosh^{-b_t}(\psi_t / 2) = \int_0^\infty e^{-\omega_t \psi_t^2 / 2} p(\omega_t |
b_t, 0) d \omega_t,
\]
where $p(\omega_t | b_t, 0)$ is the density of a $\PG(b_t, 0)$ random variate,
one may introduce the auxiliary variable $\omega_t$ so that
\[
p(y_t, \omega_t | \psi_t) = c(y_t) 2^{-b_t} e^{\kappa_t \psi_t -\omega_t
  \psi_t^2/2} p(\omega_t | b_t, 0)
\]
where $\kappa_t = a_t - b_t / 2$.  The likelihood for $(\psi_t | y_t, \omega_t)$
is proportional to the likelihood arising from the observation
\[
z_t = \psi_t + \ep_t, \; \ep_t \sim N(0, 1/\omega_t)
\]
where $z_t = \kappa_t / \omega_t$.  Thus the posterior distribution of $(\beta |
\omega)$ can be calculated using a filter forward backwards sampler under the
DLM
\begin{equation}
\label{eqn:dlm}
\begin{cases}
z_t = \psi_t + \ep_t, & \ep_t \sim N(0, 1/\omega_t) \\
\psi_t = x_t \beta_t \\
\beta_t \sim \text{AR}(1).
\end{cases}
\end{equation}
The posterior distribution of $(\omega | \beta)$ is $\prod_{t=1}^T \PG(b_t,
\psi_t)$ as constructed by \cite{polson-etal-2012}.

\subsection{Example: Dynamic Binomial Logistic Regression}

Suppose one observes a binomial outcome $y_t$ where $P(y_t = 1) = p_t$ out of
$n_t$ trials at time $t$.  Letting $\psi_t$ be the log-odds, the data generating
distribution is
\[
p(y_t | \psi_t) = c(y_t) \frac{(e^\psi_t)^{y_t}}{(1+e^{\psi_t})^{n_t}}.
\]
Thus the complete conditional $(\{\beta_t\} | \omega)$ may be simulated by the
FFBS the DLM (\ref{eqn:dlm}) where $z_t = \kappa_t / \omega_t$ and $\kappa_t =
y_t - n_t / 2$ and the complete conditional $(\omega | \beta)$ may be simulated
by sampling $\PG(n_t, \psi_t)$ for $t=1, \ldots, T$.


\subsection{Example: Dynamic Negative Binomial Regression}

Suppose that one observes counts according to $y_t \sim \NB(d, p_t)$ where $d$
is the number of ``failures'' before observing $y_t$ successes and $p_t$ is the
probability of observing a success.  Letting $\psi_t$ be the log-odds, the data
generating distribution is
\[
p(y_t | \psi_t) = c(y_t, d) \frac{(e^{\psi_t})^{y_t}}{(1+e^{\psi_t})^{y_t+d}}.
\]
In negative binomial regression, it is common to model the log-mean, $\zeta_t =
\psi_t + \log(d) = x_t \beta_t$, instead of the log-odds.  This requires only a
slight modification.  Following the work above, the complete conditional
$(\omega_t | \beta_t, d)$ is $\PG(b_t, \psi_t)$ where $b_t = y_t + d_t$.
However, the DLM used to estimate $\{\beta_t\}$ is now
\[
\begin{cases}
z_t = \psi_t + \ep_t, & \ep_t \sim N(0, 1/\omega_t) \\
\psi_t = x_t \beta_t - \log(d) \\
\beta_t = \text{AR}(1).
\end{cases}
\]
One may estimate $d$ as well using, for instance, a Metropolis-Hastings step.
We include a brief disucssion of that step in the appendix.

\section{Comparison}



\section{Conclusion}

\appendix

\section{Sampling $d$ in dynamic negative binomial regression}

We may sample $d$ by an indepedent Metropolis-Hastings or a random-walk
Metropolis-Hastings.  In either case, we need the log-likelihood of $d$.

The conditional density for a single term $y_t \sim N(d, p_t)$ is
\[
\frac{\Gamma(y_t + d)}{\Gamma(d) \Gamma(y_t) y_t} p_t^{y_t} (1-p_t)^{d} ,
\]
or 
\[
\frac{\Gamma(y_t + d)}{\Gamma(d) \Gamma(y_t) y_t} 
\Big( \frac{\mu_t}{\mu_t + d} \Big)^{y_t} \Big( \frac{d}{\mu_t + d} \Big)^d
\]
in terms of the mean $\mu_t$.  Since we chose to model $\log \mu_t = x_t
\beta_t$ it will be easier to work with the latter version.  In that case, the
log-likelihood is
\[
\ell(d|\mu, y) = \sum_{t=1}^T [ \log \Gamma(y_t + d)  - \log \Gamma(d) ]  + 
\sum_{t=1}^T y_t \log \big( \frac{\mu_t}{\mu_t + d} \Big) +
d \sum_{t=1}^T \log \Big( \frac{d}{\mu_t + d} \Big).
\]

If we assume that $d$ is a natural number then we can rid ourselves of $T$
evaluations of the gamma function.  We may expand $\Gamma(y_t + d)$ and
$\Gamma(d)$ as products, in which case the log-likelihood is
\[
\ell(d|\mu, y) = \sum_{t=1}^T \sum_{j=0}^{y_t-1} \log(d + j) + 
\sum_{t=1}^T y_t \log \big( \frac{\mu_t}{\mu_t + d} \Big) +
d \sum_{t=1}^T \log \Big( \frac{d}{\mu_t + d} \Big).
\]
We can rewrite the first term of the sum as
\[
\sum_{t=1}^T \sum_{k=1}^{\max(y_t)} \sum_{j=0}^{k-1} \log(d+j) \one \{y_t = k\}
\]
which becomes
\[
\sum_{k=1}^{\max(y_t)} n_k \sum_{j=0}^{k-1} \log(d+j)
\]
where $n_k = \{ \# y_t = k \}$.  We have thus
\begin{align*}
\sum_{k=1}^{\max(y_t)} \sum_{j=0}^{\max(y_t)-1} n_k \log(d+j) \one\{j < k\}
& = 
\sum_{j=0}^{\max(y_t)-1} \log(d+j) \sum_{k=j+1}^{\max(y_t)} n_k \\
& = \sum_{j=0}^{\max(y_t)-1} \log(d+j) G_j
\end{align*}
where $G_j = \{ \# y_t > j \}$.  Notice that $1-G_j = F(j) = \{\# y_t \leq j\}$
and that $G$ may be pre-processed.  Hence the log-likelihood is
\[
\sum_{j=0}^{\max(y_t)-1} \log(d+j) G_j + 
\sum_{t=1}^T y_t \log \big( \frac{\mu_t}{\mu_t + d} \Big) +
d \sum_{t=1}^T \log \Big( \frac{d}{\mu_t + d} \Big).
\]
Preprocessing $G$ saves us from having to compute a doubly indexed summation.


% If you have a bibliography.
% The file withe bibliography is name.bib.
\bibliography{bayeslogit}{}
\bibliographystyle{abbrvnat}

\end{document}